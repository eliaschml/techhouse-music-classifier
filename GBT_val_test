# Validation 
import pandas as pd
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score,confusion_matrix

#%% data import
tr_features = pd.read_pickle('./train_features.pkl')
tr_labels = pd.read_pickle('./train_labels.pkl')

val_features = pd.read_pickle('./val_features.pkl')
val_labels = pd.read_pickle('./val_labels.pkl')

te_features = pd.read_pickle('./test_features.pkl')
te_labels = pd.read_pickle('./test_labels.pkl')

#%% model definition and fit                           
booster1 = GradientBoostingClassifier(max_depth = 3,n_estimators =10 )
booster1.fit(tr_features, tr_labels.values.ravel())

booster2 = GradientBoostingClassifier(max_depth = 3,n_estimators =5 )
booster2.fit(tr_features, tr_labels.values.ravel())

booster3 = GradientBoostingClassifier(max_depth = 27,n_estimators =100 )
booster3.fit(tr_features, tr_labels.values.ravel())

#%% model validation & selection
for mdl in [booster1, booster2, booster3]:
    y_pred = mdl.predict(val_features)
    accuracy = accuracy_score(val_labels, y_pred)
    precision = precision_score(val_labels, y_pred, average=None)
    recall = recall_score(val_labels, y_pred, average=None)
    conf_mat = confusion_matrix(val_labels, y_pred, labels = ["Techno","House","Breakbeat", "Ambient"])
    print(' \n-- A: {} / P: {} / R: {}'.format(accuracy,precision, recall))
    print(conf_mat)

#%% model testing 
    
y_pred = booster2.predict(te_features)
accuracy = accuracy_score(te_labels, y_pred)
precision = precision_score(te_labels, y_pred, average=None)
recall = recall_score(te_labels, y_pred, average=None)
conf_mat = confusion_matrix(te_labels, y_pred, labels = ["Techno","House","Breakbeat", "Ambient"])
print(' \n-- A: {} / P: {} / R: {}'.format(accuracy,precision, recall))
print(conf_mat) 
